{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 점수 예측 분포도 그려보기\n",
    "\n",
    "dev.csv에 들어있는 label 결과를 모델이 얼마나 잘 예측하고 있는 지를 측정하기 위한 코드를 작성하고, 가장 점수 차이가 많이 나는 상위 20개의 결과물을 csv로 내보내고, 히스토그램 및 산점도를 그려보기로 했습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt \n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# 1. Model 클래스 정의\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, model_name, lr):\n",
    "    \n",
    "\t\t    # pl.LightningModule 초기화\n",
    "        super().__init__()\n",
    "        \n",
    "\t      # 모델명(model_name) 및 plm(pretrained learning model)을 불러옵니다. \n",
    "\t      # transformers.AutoModelForSequenceClassification를 사용 \n",
    "\t      # num_labels=1 -> 예측해야 할 값이 하나 (유사도 점수)\n",
    "        self.model_name = model_name\n",
    "        self.plm = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "            pretrained_model_name_or_path=model_name, num_labels=1\n",
    "        )\n",
    "\n",
    "\t\t# forward: 입력값 (input_ids, attention_mask) -> plm -> logits 반환\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.plm(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs['logits']\n",
    "\n",
    "# 2. dev.csv 데이터 로드\n",
    "dev_data = pd.read_csv('../data/dev.csv')\n",
    "\n",
    "# 3. 모델 로드 및 평가 모드 전환\n",
    "model = torch.load('model_large_20_msk.pt')\n",
    "model = torch.load('model_large_20.pt')\n",
    "model.eval()\n",
    "\n",
    "# 4. 토크나이저 준비\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('klue/roberta-small')\n",
    "\n",
    "# 5. 데이터 전처리 (dev.csv 텍스트를 토큰화)\n",
    "# 두 문장을 '[SEP]' 토큰으로 연결\n",
    "# return_tensors='pt' -> 토큰화된 데이터를 모델에 입력할 수 있도록 함\n",
    "def preprocess_data(data, tokenizer):\n",
    "    texts = ['[SEP]'.join([item['sentence_1'], item['sentence_2']]) for _, item in data.iterrows()]\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=160)\n",
    "    return inputs\n",
    "\n",
    "# 결과값을 inputs에 넣음\n",
    "inputs = preprocess_data(dev_data, tokenizer)\n",
    "\n",
    "# 6. 모델 예측 수행 \n",
    "# torch.no_grad(): 모델 -> 예측값 계산, 역전파 비활성화\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "    predictions = outputs.squeeze().numpy()\n",
    "\n",
    "# 7. 실제 값 불러오기\n",
    "actuals = dev_data['label'].values\n",
    "\n",
    "# 8. 예측값과 실제값 비교 (차이 계산)\n",
    "differences = abs(actuals - predictions)\n",
    "\n",
    "# 9. 차이가 큰 데이터 상위 20개 출력\n",
    "dev_data['predicted'] = predictions\n",
    "dev_data['difference'] = differences\n",
    "top_differences = dev_data.nlargest(20, 'difference')\n",
    "\n",
    "# 차이가 큰 20개의 데이터를 csv 파일 형태로 저장\n",
    "print(\"차이가 큰 상위 20개 데이터:\\n\", top_differences[['sentence_1', 'sentence_2', 'label', 'predicted', 'difference']].to_csv('difference_without_mask.csv', index=False))\n",
    "\n",
    "# 10. 예측값과 실제값 비교 시각화 (히스토그램)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(actuals, bins=20, alpha=0.5, label='Actuals', color='blue', edgecolor='black')\n",
    "plt.hist(predictions, bins=20, alpha=0.5, label='Predictions', color='red', edgecolor='black')\n",
    "plt.xlabel('Similarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Actual vs Predicted Similarity Score Distribution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 11. 예측값과 실제값 차이 시각화 (Scatter Plot)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(actuals, predictions, alpha=0.5)\n",
    "plt.plot([0, 5], [0, 5], color='red', linestyle='--')  # 완벽히 일치하는 경우\n",
    "plt.xlabel('Actual Similarity')\n",
    "plt.ylabel('Predicted Similarity')\n",
    "plt.title('Actual vs Predicted Similarity (STS)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과물 (그래프) \n",
    "### 마스킹을 적용한 모델  \n",
    "\n",
    "![model_large_20_msk.pt](images/model_large_20_msk_score_distribution_graph.png)\n",
    "\n",
    "### 마스킹을 적용하지 않은 모델 (히스토그램)\n",
    "\n",
    "![model_large_20_msk.pt](images/model_large_20_score_distribution_graph.png)\n",
    "\n",
    "### 마스킹을 적용하지 않은 모델 (산점도)\n",
    "\n",
    "![scatter_plot.pt](images/scatter_plot.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
